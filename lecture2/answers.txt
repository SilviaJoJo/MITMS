【2】Shell Tools and Scripting
1.Read man ls and write an ls command that lists files in the following manner

-Includes all files, including hidden files
-Sizes are listed in human readable format (e.g. 454M instead of 454279954)
-Files are ordered by recency
-Output is colorized

A sample output would look like this

 -rw-r--r--   1 user group 1.1M Jan 14 09:53 baz
 drwxr-xr-x   5 user group  160 Jan 14 09:53 .
 -rw-r--r--   1 user group  514 Jan 14 06:42 bar
 -rw-r--r--   1 user group 106M Jan 13 12:12 foo
 drwx------+ 47 user group 1.5K Jan 12 18:08 ..
ls -alht --color=auto (First of all, we use -a to list all files, including hidden files; then -l to use a long listing
format; then -h to show in human-readable format; then -t to sort by time, newest first; then --color=auto to colorize the
output; finally, all flags could be integrated into one)
2.Write bash functions marco and polo that do the following. Whenever you execute marco the current working directory
should be saved in some manner, then when you execute polo, no matter what directory you are in, polo should cd you back
to the directory where you executed marco. For ease of debugging you can write the code in a file marco.sh and (re)load
the definitions to your shell by executing source marco.sh.
see marco.sh
command: source marco.sh; marco; (maybe change to another dir) polo
3.Say you have a command that fails rarely. In order to debug it you need to capture its output but it can be time
consuming to get a failure run. Write a bash script that runs the following script until it fails and captures its
standard output and error streams to files and prints everything at the end. Bonus points if you can also report how many
runs it took for the script to fail.

 #!/usr/bin/env bash

 n=$(( RANDOM % 100 ))

 if [[ n -eq 42 ]]; then
    echo "Something went wrong"
    >&2 echo "The error was using magic numbers" #>2 output.txt (redirect to a file) or >2& (redirect to stderr)
    exit 1
 fi

 echo "Everything went according to plan"
see failureCheck.sh
4.As we covered in the lecture find’s -exec can be very powerful for performing operations over the files we are searching
for. However, what if we want to do something with all the files, like creating a zip file? As you have seen so far
commands will take input from both arguments and STDIN. When piping commands, we are connecting STDOUT to STDIN, but
some commands like tar take inputs from arguments. To bridge this disconnect there’s the xargs command which will execute
a command using STDIN as arguments. For example ls | xargs rm will delete the files in the current directory.
Your task is to write a command that recursively finds all HTML files in the folder and makes a zip with them. Note that
your command should work even if the files have spaces (hint: check -d flag for xargs).
find ./HTML/ -type f -name "*.html" | xargs -d '\n' zip HTML.zip
1)Pattern: find . -path '*/test/*.py' -type f (. represents the current directory)
the find command returns:
./HTML/HTML/2.html
./HTML/1.html
which we will later process (notice that different results are separated by '\n')
2)the output of find will piped to xargs, which takes each file name as a separate argument and pass them to zip
5.(Advanced) Write a command or script to recursively find the most recently modified file in a directory. More generally,
can you list all files by recency?
find . -type f | xargs -d '\n' ls -lt